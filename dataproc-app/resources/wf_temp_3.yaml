jobs:
  pysparkJob:
    mainPythonFileUri: gs://yt-demo-dev-dataproc-app/spark/simple_spark_job3.py
    args:
      - "--source_bucket=app-bucket-12344"
      - "--source_format=json"
      - "--destination=bigquery"
      - "--destination_name=dataset_table_123"
      - "--opt_params=
          --debugg
          --model=RL
          --x=200
          --y=100"
  stepId: simple-job3
  labels:
    project: yt-demo-dev-dataproc
placement:
  managedCluster:
    clusterName: yt-demo-wf-temp-dev-cluster
    config:
      configBucket: yt-demo-dev-dataproc-staging
      tempBucket: yt-demo-dev-dataproc-temp
      gceClusterConfig:
        zoneUri: europe-west1-b
      masterConfig:
        diskConfig:
          bootDiskSizeGb: 50
        machineTypeUri: n1-standard-4
      softwareConfig:
        imageVersion: '1.4'
        properties:
          dataproc:pip.packages: tokenizers==0.10.1,datasets==1.5.0
      workerConfig:
        diskConfig:
          bootDiskSizeGb: 50
        machineTypeUri: n1-standard-4
        numInstances: 2